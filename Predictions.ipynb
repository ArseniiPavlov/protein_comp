{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import InceptionV3_fine_tune2\n",
    "import img_proc_scikit\n",
    "from PIL import Image, ImageFile\n",
    "from os import path, listdir, makedirs, fsdecode, getcwd\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "\n",
    "train_df = img_proc_scikit.TrainData('train.csv').make_train()\n",
    "img_rows, img_cols = 299, 299  # Resolution of inputs\n",
    "channel = 3\n",
    "num_classes = 28\n",
    "batch_size = 12\n",
    "\n",
    "model = InceptionV3_fine_tune2.InceptionV3_make('InceptionV3_ft2.h5', 28)\n",
    "f1_score = InceptionV3_fine_tune2.f1\n",
    "\n",
    "train_dir = getcwd() + '\\\\train'\n",
    "train_df['Preds'] = None\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda2\\envs\\ML_env\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "for line in train_df.values[:100]:\n",
    "    sample = img_proc_scikit.save_rgb_image(line[0], line[2], train_dir, labeled_dir=None, save_img=False)\n",
    "    sample = resize(sample, (299, 299))\n",
    "    sample = np.array(sample)\n",
    "    line[3] = model.predict(np.expand_dims(sample, axis=0), batch_size=1)[0]\n",
    "    i += 1\n",
    "    if (i % 100) == 0:\n",
    "        print('{} images were predicted'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('train_df.pkl', 'rb') as f:\n",
    "    train_df = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Estimators = [RFC(n_estimators=50, max_depth=25) for x in range(28)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esatimator no. 0 was trained\n",
      "Esatimator no. 1 was trained\n",
      "Esatimator no. 2 was trained\n",
      "Esatimator no. 3 was trained\n",
      "Esatimator no. 4 was trained\n",
      "Esatimator no. 5 was trained\n",
      "Esatimator no. 6 was trained\n",
      "Esatimator no. 7 was trained\n",
      "Esatimator no. 8 was trained\n",
      "Esatimator no. 9 was trained\n",
      "Esatimator no. 10 was trained\n",
      "Esatimator no. 11 was trained\n",
      "Esatimator no. 12 was trained\n",
      "Esatimator no. 13 was trained\n",
      "Esatimator no. 14 was trained\n",
      "Esatimator no. 15 was trained\n",
      "Esatimator no. 16 was trained\n",
      "Esatimator no. 17 was trained\n",
      "Esatimator no. 18 was trained\n",
      "Esatimator no. 19 was trained\n",
      "Esatimator no. 20 was trained\n",
      "Esatimator no. 21 was trained\n",
      "Esatimator no. 22 was trained\n",
      "Esatimator no. 23 was trained\n",
      "Esatimator no. 24 was trained\n",
      "Esatimator no. 25 was trained\n",
      "Esatimator no. 26 was trained\n",
      "Esatimator no. 27 was trained\n"
     ]
    }
   ],
   "source": [
    "targets = np.array(list(map(np.array,train_df['Cat'].values)))\n",
    "X = np.array(list(map(np.array,train_df['Preds'].values)))\n",
    "for column, estimator in enumerate(Estimators):\n",
    "    y_pred = targets[:,column]\n",
    "    estimator.fit(X, y_pred) \n",
    "    print('Esatimator no. {} was trained'.format(column))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Forest_preds'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 lines were predicted\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for line in train_df.values[:100]:\n",
    "    line[4] = [estimator.predict([line[3]])[0] for estimator in Estimators]\n",
    "    i += 1\n",
    "    if (i % 100) == 0:\n",
    "        print('{} lines were predicted'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: Forest_preds, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Forest_preds'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('train_df.pkl', 'wb') as f:\n",
    "    pickle.dump(train_df, f)\n",
    "\n",
    "with open('Forests.pkl', 'wb') as f:\n",
    "    pickle.dump(Estimators, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "1    [1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "2    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "3    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: Forest_preds, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Forest_preds'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = f1_score(np.array(list(map(np.array,train_df['Cat'].values[0:100]))), np.array(list(map(np.array,train_df['Forest_preds'].values[0:100]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68883055"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.eval(scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('filename.pkl', 'rb') as f:\n",
    "#    clf = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
